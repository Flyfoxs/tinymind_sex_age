{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-21 23:46:46,821 util_cache_file.py[79] DEBUG fn:get_tfidf, para:[], kw:{}\n",
      "2018-09-21 23:46:46,823 util_cache_file.py[21] DEBUG try to read cache from file:./cache/get_tfidf_[]_{}.pkl, type:pkl\n",
      "2018-09-21 23:46:49,495 util_cache_file.py[26] DEBUG Load to <class 'pandas.core.sparse.frame.SparseDataFrame'> with density:0.00030081144947150695 for pkl@./cache/get_tfidf_[]_{}.pkl\n",
      "2018-09-21 23:46:51,053 util_cache_file.py[35] DEBUG Return 72727 resut from file cache:./cache/get_tfidf_[]_{}.pkl\n"
     ]
    }
   ],
   "source": [
    "from  tiny.package import *\n",
    "from  tiny.util import *\n",
    "from  tiny.lda import *\n",
    "from  tiny.tfidf import *\n",
    "tmp = get_tfidf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-6ae3630cd7f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/dev/python/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mstat_func\u001b[0;34m(self, axis, skipna, level, numeric_only, min_count, **kwargs)\u001b[0m\n\u001b[1;32m   7293\u001b[0m                                       skipna=skipna, min_count=min_count)\n\u001b[1;32m   7294\u001b[0m         return self._reduce(f, name, axis=axis, skipna=skipna,\n\u001b[0;32m-> 7295\u001b[0;31m                             numeric_only=numeric_only, min_count=min_count)\n\u001b[0m\u001b[1;32m   7296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7297\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mset_function_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstat_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/python/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_reduce\u001b[0;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[1;32m   5707\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5708\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5709\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5710\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/python/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   5696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5697\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5698\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5700\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_agg_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/python/anaconda3/lib/python3.6/site-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36m_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minvalid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0;31m# we want to transform an object array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/python/anaconda3/lib/python3.6/site-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[1;32m    126\u001b[0m                         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/python/anaconda3/lib/python3.6/site-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36mnansum\u001b[0;34m(values, axis, skipna, min_count)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mbottleneck_switch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mnansum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m     \u001b[0mdtype_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype_max\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_float_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/python/anaconda3/lib/python3.6/site-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36m_get_values\u001b[0;34m(values, skipna, fill_value, fill_value_typ, isfinite, copy)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype_ok\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mputmask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tmp.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-21 23:38:07,796 util_log.py[33] INFO Begin to run summary_top_for_individual_file with:['./output/start_close/deviceid_package_start_close_40_36_33897608_34837990.csv'], {'gp_col': 'p_type', 'top': 3}\n",
      "2018-09-21 23:38:07,796 util_log.py[33] INFO Begin to run summary_top_for_individual_file with:['./output/start_close/deviceid_package_start_close_40_37_34837990_35780089.csv'], {'gp_col': 'p_type', 'top': 3}\n",
      "2018-09-21 23:38:07,796 util_log.py[33] INFO Begin to run summary_top_for_individual_file with:['./output/start_close/deviceid_package_start_close_40_38_35780089_36720940.csv'], {'gp_col': 'p_type', 'top': 3}\n",
      "2018-09-21 23:38:07,802 util_cache_file.py[79] DEBUG fn:cal_duration_for_partition, para:['deviceid_package_start_close_40_37_34837990_35780089.csv'], kw:{}\n",
      "2018-09-21 23:38:07,802 util_cache_file.py[79] DEBUG fn:cal_duration_for_partition, para:['deviceid_package_start_close_40_38_35780089_36720940.csv'], kw:{}\n",
      "2018-09-21 23:38:07,804 util_cache_file.py[79] DEBUG fn:cal_duration_for_partition, para:['deviceid_package_start_close_40_36_33897608_34837990.csv'], kw:{}\n",
      "2018-09-21 23:38:07,806 util_cache_file.py[21] DEBUG try to read cache from file:./cache/cal_duration_for_partition_['deviceid_package_start_close_40_38_35780089_36720940.csv']_{}.csv, type:csv\n",
      "2018-09-21 23:38:07,806 util_cache_file.py[21] DEBUG try to read cache from file:./cache/cal_duration_for_partition_['deviceid_package_start_close_40_37_34837990_35780089.csv']_{}.csv, type:csv\n",
      "2018-09-21 23:38:07,807 util_cache_file.py[21] DEBUG try to read cache from file:./cache/cal_duration_for_partition_['deviceid_package_start_close_40_36_33897608_34837990.csv']_{}.csv, type:csv\n",
      "2018-09-21 23:38:16,136 util_cache_file.py[35] DEBUG Return 995527 resut from file cache:./cache/cal_duration_for_partition_['deviceid_package_start_close_40_37_34837990_35780089.csv']_{}.csv\n",
      "2018-09-21 23:38:16,138 util_log.py[33] INFO Begin to run get_package_label with:[], {}\n",
      "2018-09-21 23:38:16,158 util_log.py[38] INFO cost:   0.02 sec: ==='get_package_label' end ([], {}) \n",
      "2018-09-21 23:38:16,376 util_cache_file.py[35] DEBUG Return 1015547 resut from file cache:./cache/cal_duration_for_partition_['deviceid_package_start_close_40_38_35780089_36720940.csv']_{}.csv\n",
      "2018-09-21 23:38:16,379 util_log.py[33] INFO Begin to run get_package_label with:[], {}\n",
      "2018-09-21 23:38:16,397 util_log.py[38] INFO cost:   0.02 sec: ==='get_package_label' end ([], {}) \n",
      "2018-09-21 23:38:16,919 util_cache_file.py[35] DEBUG Return 1054254 resut from file cache:./cache/cal_duration_for_partition_['deviceid_package_start_close_40_36_33897608_34837990.csv']_{}.csv\n",
      "2018-09-21 23:38:16,922 util_log.py[33] INFO Begin to run get_package_label with:[], {}\n",
      "2018-09-21 23:38:16,945 util_log.py[38] INFO cost:   0.02 sec: ==='get_package_label' end ([], {}) \n",
      "2018-09-21 23:38:19,632 util_log.py[38] INFO cost:  11.84 sec: ==='summary_top_for_individual_file' end (['./output/start_close/deviceid_package_start_close_40_37_34837990_35780089.csv'], {'gp_col': 'p_type', 'top': 3}) \n",
      "2018-09-21 23:38:19,893 util_log.py[38] INFO cost:  12.10 sec: ==='summary_top_for_individual_file' end (['./output/start_close/deviceid_package_start_close_40_38_35780089_36720940.csv'], {'gp_col': 'p_type', 'top': 3}) \n",
      "2018-09-21 23:38:20,555 util_log.py[38] INFO cost:  12.76 sec: ==='summary_top_for_individual_file' end (['./output/start_close/deviceid_package_start_close_40_36_33897608_34837990.csv'], {'gp_col': 'p_type', 'top': 3}) \n",
      "Process ForkPoolWorker-2:\n",
      "Process ForkPoolWorker-1:\n",
      "Process ForkPoolWorker-3:\n",
      "Process ForkPoolWorker-4:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/lali2/dev/python/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/lali2/dev/python/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/lali2/dev/python/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/lali2/dev/python/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/lali2/dev/python/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/lali2/dev/python/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/lali2/dev/python/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/Users/lali2/dev/python/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/Users/lali2/dev/python/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/Users/lali2/dev/python/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/lali2/dev/python/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/Users/lali2/dev/python/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/Users/lali2/dev/python/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/Users/lali2/dev/python/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/lali2/dev/python/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Users/lali2/dev/python/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Users/lali2/dev/python/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Users/lali2/dev/python/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/lali2/dev/python/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/Users/lali2/dev/python/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/Users/lali2/dev/python/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/Users/lali2/dev/python/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from tiny.group_label import *\n",
    "gp_col = 'p_type'\n",
    "top=3\n",
    "rootdir = './output/start_close/'\n",
    "list_ = os.listdir(rootdir)  # 列出文件夹下所有的目录与文件\n",
    "path_list = sorted(list_, reverse=True)\n",
    "path_list = [os.path.join(rootdir, item) for item in path_list if item.endswith('csv')]\n",
    "\n",
    "from multiprocessing import Pool as ThreadPool\n",
    "\n",
    "pool = ThreadPool(processes=4)\n",
    "\n",
    "process_file = partial(summary_top_for_individual_file, gp_col=gp_col, top=top)\n",
    "results = pool.map(process_file, path_list[:3])\n",
    "\n",
    "results = [item for item in results if len(item)>0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1827, 102)\n",
      "(1927, 102)\n",
      "(1924, 102)\n",
      "102\n"
     ]
    }
   ],
   "source": [
    "for item in results:\n",
    "    print(item.shape)\n",
    "\n",
    "xx = pd.concat(results)\n",
    "\n",
    "print(len(list(xx.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#group by specific label\n",
    "#p_type, p_sub_type, combine_type, package\n",
    "gp_col = 'p_type' \n",
    "top = 3\n",
    "label_list = []\n",
    "value = 'package_cnt_daily'#,'package_dur_daily', 'duration_sum'\n",
    "\n",
    "#group by top#n\n",
    "gp = ex_input.groupby(['device', gp_col]).agg({'start':['count'], gp_col:['nunique'], 'duration':['sum'], 'start_base':['nunique']})\n",
    "gp.columns = [\"_\".join(x) for x in gp.columns.ravel()]\n",
    "\n",
    "gp[f'{gp_col}_cnt_daily'] = gp[f'start_count'] / gp['start_base_nunique']\n",
    "gp[f'{gp_col}_dur_daily'] = gp[f'duration_sum'] / gp['start_base_nunique']\n",
    "\n",
    "gp = gp.reset_index()\n",
    "gp = gp.sort_values(['device',f'{gp_col}_cnt_daily'], ascending=False)\n",
    "gp['cum_sn'] = gp.groupby('device').cumcount()\n",
    "gp = gp[gp.cum_sn < top]\n",
    "\n",
    "gp\n",
    "gp00 = gp.pivot(index='device', columns='cum_sn', values=f'{gp_col}_cnt_daily')\n",
    "gp00.columns = [f'{gp_col}_cnt_top#{item}' for item in gp00.columns]\n",
    "\n",
    "gp01 = gp.pivot(index='device', columns='cum_sn', values=f'{gp_col}_dur_daily')\n",
    "gp01.columns = [f'{gp_col}_dur_top#{item}' for item in gp01.columns]\n",
    "\n",
    "gp02 = gp.pivot(index='device', columns='cum_sn', values=gp_col)\n",
    "gp02.columns = [f'{gp_col}_name_top#{item}' for item in gp02.columns]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "gp = ex_input.groupby(['device', gp_col]).agg({'start':['count'],  'duration':['sum'], 'start_base':['nunique']})\n",
    "gp.columns = [\"_\".join(x) for x in gp.columns.ravel()]\n",
    "\n",
    "gp[f'{gp_col}_count'] = gp.count(axis=1)\n",
    "gp[f'{gp_col}_cnt_daily'] = gp[f'start_count'] / gp['start_base_nunique']\n",
    "gp[f'{gp_col}_dur_daily'] = gp[f'duration_sum'] / gp['start_base_nunique']\n",
    "gp\n",
    "gp = gp.reset_index()\n",
    "gp = gp.sort_values(['device',f'{gp_col}_cnt_daily'], ascending=False)\n",
    "gp\n",
    "gp['cum_sn'] = gp.groupby('device').cumcount()\n",
    "gp11 = gp.pivot(index='device', columns=gp_col, values=f'{gp_col}_cnt_daily')\n",
    "gp12 = gp.pivot(index='device', columns=gp_col, values=f'{gp_col}_dur_daily')\n",
    "\n",
    "\n",
    "\n",
    "tmp = ex_input.groupby('device')[gp_col].nunique().to_frame()\n",
    "tmp.rename(columns={gp_col:f'{gp_col}_count'}, inplace=True)\n",
    " \n",
    "\n",
    "df = pd.concat([gp00, gp01, gp02, gp11, gp12, tmp], axis=1)\n",
    "\n",
    "df.fillna(0)\n",
    " \n",
    "# gp[[f'{gp_col}_count','cum_sn']] = gp.groupby('device').agg({'duration_sum':'count', 'package_nunique':'cumcount'})\n",
    "# gp\n",
    "#len(list(gp.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = get_package_label()\n",
    "len(tmp.p_type.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "pd.set_option('display.height', 1000)\n",
    "df['month'] = df.start_base.dt.to_period('M')\n",
    "tmp = df.groupby('month')['month'].count()\n",
    "tmp = tmp.to_frame()\n",
    "tmp.rename(columns={'month':'count'}, inplace=True)\n",
    "tmp.reset_index(inplace=True)\n",
    "#tmp.dtypes\n",
    "\n",
    "#tmp.plot.line()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tmp.set_index('month', inplace=True)\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total=df.groupby(['device']).agg({'package':'nunique', 'duration':'sum'})\n",
    "\n",
    "\n",
    "gp = df.groupby(['device', 'weekday']).agg({'package':'nunique', 'day_duration':'sum'})\n",
    "gp\n",
    "gp.reset_index(inplace=True)\n",
    "gp\n",
    "gp1=gp.pivot(index='device', columns='weekday',values='package')\n",
    "gp1.columns = [f'package_{col}' for col in gp1.columns]\n",
    "\n",
    "gp2=gp.pivot(index='device', columns='weekday',values='day_duration')\n",
    "gp2.columns = [f'duration_{col}' for col in gp2.columns]\n",
    "\n",
    "gp1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge = pd.concat([gp1, gp2, wk, total], axis=1)\n",
    "merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#转换为Percentage\n",
    "type_= 'package'\n",
    "for col in [col for col in merge.columns if f'{type_}_' in col]:\n",
    "    #print(col)\n",
    "    merge[col] = merge[col]/merge[type_]\n",
    "    \n",
    "type_= 'duration'\n",
    "for col in [col for col in merge.columns if f'{type_}_' in col]:\n",
    "   # print(col)\n",
    "    merge[col] = merge[col]/merge[type_]\n",
    "    \n",
    "merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in tmp.columns:\n",
    "    if 'Unknown' in col:\n",
    "        print(col)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pkg_label = get_package_label()\n",
    "pkg_label.set_index('package', inplace=True)\n",
    "pkg_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "extend_time_span(version=0, trunc_long_time=False, mini=True, groupby=['device'], prefix='tol')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns = [ col for col in install.columns ]\n",
    "print(columns[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "cntTf_app = vectorizer.fit_transform(apps)\n",
    "\n",
    "str(cntTf_app[:3])\n",
    "# cntTf_app = pd.DataFrame(cntTf_app,\n",
    "#                          columns=vectorizer.get_feature_names(),\n",
    "#                          index=deviceid_packages.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mini = get_start_closed()\n",
    "tmp[tmp.device.isin(mini.device)][['device','duration_max_min', 'tol_day_cnt_nunique', 'gap']].sort_values('gap', ascending=False)\n",
    "\n",
    "\n",
    "#f993126b72f6297440c2dc8534b20a0b  49\n",
    "#fbf985012f537449b455d6a554479f8b  1161\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from  tiny.lda import *\n",
    "get_lda_from_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "device= 'fa68862f9484c62aca5c3a4b8a2c70bc'\n",
    "mini[mini.device==device].sort_values('start')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp[tmp.device==device]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df2.set_index('device', inplace=True)\n",
    "df.sort_index(ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "split.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(pd.to_datetime('1488332491588', unit='ms'))  #fc6383d2bdb463fd01db6731594a6d36\t07e967d75aab2f6a52c558695a572a7c\n",
    "print(pd.to_datetime('1488332506604', unit='ms'))\n",
    "print(pd.to_datetime('1488363700875', unit='ms'))\n",
    "print(pd.to_datetime('1488363707487', unit='ms'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp = extend_time(tmp,2)\n",
    "#tmp['start'].astype\n",
    "#tmp['start'] = pd.to_datetime(tmp['start'])\n",
    "#tmp['start'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# def extend_percent(df):\n",
    "#     total = get_percent_duration(df, ['device'], 'total')\n",
    "\n",
    "#     max_week = get_max_week(df)\n",
    "\n",
    "#     merge = df.merge(max_week, on=['device', 'weekbegin'])\n",
    "\n",
    "#     max = get_percent_duration(merge, ['device'], prefix='max')\n",
    "\n",
    "#     return pd.concat( [total, max], axis=1 )\n",
    "\n",
    "\n",
    "# total = get_percent_duration(df, ['device'], 'total')\n",
    "\n",
    "\n",
    "# df = tmp\n",
    "# max_week = get_max_week(df)\n",
    "# max_week.head()\n",
    "# merge = df.merge(max_week, on=['device', 'weekbegin'])\n",
    "\n",
    " \n",
    "# def get_percent_duration(df, groupby=['device', 'weekday'], prefix=None):\n",
    "#     prefix = groupby[-1] if prefix is None else prefix\n",
    "#     columns = [key for key in df.columns if 'span_' in key]\n",
    "#     gp_map = [(key, 'sum') for key in columns if 'span_' in key]\n",
    "#     gp_map = dict(gp_map)\n",
    "#     # print(gp_map)\n",
    "\n",
    "#     gp_map['package'] = 'nunique'\n",
    "#     gp_map['start_base'] = 'nunique'\n",
    "#     df = df.groupby(groupby).agg(gp_map)\n",
    "#     #     df = df.groupby(groupby).agg({'span_0':'sum','span_1':'sum','span_2':'sum',\n",
    "#     #                                                  'span_3':'sum','package':'nunique' })\n",
    "#     df['total'] = df[[key for key in columns if 'span_' in key]].sum(axis=1)\n",
    "\n",
    "#     for col in columns:\n",
    "#         df[f'{col}_p'] = round(df[col] / df['total'], 3)\n",
    "\n",
    "#     df.rename({'package':'package_cnt', 'start_base':'start_base_cnt'}, axis=1, inplace=True)\n",
    "\n",
    "#     df.columns = [f'{prefix}_{key}' for key in df.columns]\n",
    "#     return df\n",
    "\n",
    "per = extend_percent(tmp)\n",
    "per.head()\n",
    "\n",
    "# max_week = get_max_week(tmp)\n",
    "# max_week\n",
    "\n",
    "# merge= tmp.merge(max_week, on = ['device','weekbegin'])\n",
    "\n",
    "# print(len(merge))\n",
    "\n",
    "# get_percent_duration(merge, ['device'], prefix='max')\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "per\n",
    "#tmp[tmp.device=='fc6383d2bdb463fd01db6731594a6d36'].sort_values('start')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tmp['start_base']  = tmp['start'].dt.date\n",
    "# tmp = tmp[tmp.device.isin(['fff885dafce62310951c835247f30a38',\n",
    "# 'fc65f1731b785a8ce82d20a30dee9259'])]\n",
    "\n",
    "df = tmp.groupby(['device','weekbegin']).package.nunique().to_frame().reset_index()\n",
    "\n",
    "# .to_frame().reset_index()\n",
    "# df.sort_values(['device', 'package'])\n",
    "\n",
    "df.sort_values(by=['device', 'package', 'weekbegin'], ascending=False).groupby('device').nth(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xx = df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lightgbm.sklearn import LGBMRegressor, LGBMClassifier\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "import lightgbm as lgb\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "from tiny.lda import *\n",
    "from  tiny.util import *\n",
    "\n",
    "# New add\n",
    "# deviceid_train.rename({'device_id':'device'}, axis=1, inplace=True)\n",
    "deviceid_train = get_lda_feature()\n",
    "deviceid_train2 = get_lda_from_usage(mini=mini)\n",
    "\n",
    "core_list = ['0', '1', '2', '3','4']\n",
    "# for col in core_list:\n",
    "#     deviceid_train_2[col] =  deviceid_train_2[col].apply(lambda val: 1 if val > 0 else 0)\n",
    "deviceid_train = pd.concat([deviceid_train,deviceid_train2[core_list] ], axis=1)\n",
    "\n",
    "deviceid_train = extend_feature(span_no=24, input=deviceid_train, trunc_long_time=False)\n",
    "\n",
    "#deviceid_train = extend_feature(span_no=4,input=deviceid_train,  trunc_long_time=False)\n",
    "\n",
    "\n",
    "\n",
    "#print(len(deviceid_train))\n",
    "#deviceid_train.groupby('max_day_cnt')['max_day_cnt'].count()\n",
    "\n",
    "#\n",
    "#\n",
    "# col_drop = [item for item in deviceid_train.columns if 'max_' in str(item)]\n",
    "# deviceid_train.drop(columns=col_drop, inplace=True )\n",
    "\n",
    "#deviceid_train.drop(columns=['tfidf_sum'], inplace=True )\n",
    "deviceid_train.head()\n",
    "\n",
    "\n",
    "train=deviceid_train[deviceid_train['sex'].notnull()]\n",
    "test=deviceid_train[deviceid_train['sex'].isnull()]\n",
    "\n",
    "X = train.drop(['sex', 'age', 'sex_age', 'device'], axis=1)\n",
    "Y = train['sex_age']\n",
    "Y_CAT = pd.Categorical(Y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y_CAT.labels, test_size=0.3, random_state=666)\n",
    "# lgb_train = lgb.Dataset(X_train, label=y_train)\n",
    "# lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'max_depth': 3,\n",
    "    'metric': {'multi_logloss'},\n",
    "    'num_class': 22,\n",
    "    'objective': 'multiclass',\n",
    "    'random_state': 47,\n",
    "\n",
    "    \"min_data_in_leaf\":1000,\n",
    "    'verbose': -1\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "gbm = LGBMClassifier(\n",
    "        n_estimators=1000,\n",
    "\n",
    "        )\n",
    "\n",
    "gbm.set_params(**params)\n",
    "\n",
    "print(gbm)\n",
    "\n",
    "gbm.fit(X_train, y_train, eval_set=[(X_test, y_test)],early_stopping_rounds=100,)\n",
    "\n",
    "#y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration)#\n",
    "print('Feature importances:', list(gbm.feature_importances_))\n",
    "\n",
    "best = round(gbm.best_score_.get('valid_0').get('multi_logloss'), 5)\n",
    "best\n",
    "\n",
    "\n",
    "pre_x=test.drop(['sex','age','sex_age','device'],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub=pd.DataFrame(gbm.predict_proba(pre_x.values,num_iteration=gbm.best_iteration_))\n",
    "\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp = extend_cols(tmp)\n",
    "tmp, tmp_new = split_days(tmp)\n",
    "\n",
    "tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp, tmp_new = split_days(tmp)\n",
    "tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainn_label = get_train_label()\n",
    "trainn_label.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from  tiny.util import *\n",
    "\n",
    "tmp = extend_feature( span_no=2, trunc_long_time=False, mini=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp = extend_time_span(version=1, trunc_long_time=False, mini=True, groupby=['device'], prefix='tol')\n",
    "tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tiny.lda import *\n",
    "from  tiny.util import *\n",
    "\n",
    "tmp = extend_package(version=1)\n",
    "tmp.head(3).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp = tmp/tmp\n",
    "\n",
    "tmp.head(3).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp.head(3).count(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
