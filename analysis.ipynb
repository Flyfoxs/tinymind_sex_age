{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lali2/dev/python/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/Users/lali2/dev/python/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/Users/lali2/dev/python/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35000, 44) (35000,) (15000, 44) (15000,)\n",
      "(35000, 22)\n",
      "Train on 35000 samples, validate on 15000 samples\n",
      "Epoch 1/2\n",
      "35000/35000 [==============================] - 1s 17us/step - loss: 3.0920 - val_loss: 3.0684\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.06844, saving model to ./model/checkpoint/ensemble.h5\n",
      "Epoch 2/2\n",
      "35000/35000 [==============================] - 0s 13us/step - loss: 3.0613 - val_loss: 3.0401\n",
      "\n",
      "Epoch 00002: val_loss improved from 3.06844 to 3.04011, saving model to ./model/checkpoint/ensemble.h5\n"
     ]
    }
   ],
   "source": [
    "from keras import Input, Model\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from keras.layers import Dropout, Dense\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tiny.util import attach_device_train_label, replace_invalid_filename_char\n",
    "from utils_.util_log import *\n",
    "\n",
    "def read_result_for_ensemble(file):\n",
    "    #file = f'./output/best/{name}.h5'\n",
    "    store = pd.HDFStore(file)\n",
    "    return store[\"train\"], store[\"label\"], store[\"test\"]\n",
    "\n",
    "def get_label_cat():\n",
    "    label =  attach_device_train_label(None)\n",
    "    return pd.Categorical(label.sex_age).categories\n",
    "\n",
    "\n",
    "file_list = [\n",
    "    './output/best/2.621213_2510_xgb.h5' ,\n",
    "    './output/best/2.635281090037028_1569_dnn.h5' ,\n",
    "]\n",
    "\n",
    "train_list =[]\n",
    "label_list = []\n",
    "test_list  = []\n",
    "for file in file_list:\n",
    "    train, label, test = read_result_for_ensemble(file)\n",
    "\n",
    "    train_list.append(train)\n",
    "    label_list.append(label)\n",
    "    test_list.append(test)\n",
    "\n",
    "train = pd.concat(train_list, axis=1)\n",
    "test = pd.concat(test_list, axis=1)\n",
    "label = label_list[0]\n",
    "\n",
    "\n",
    "train = train.sort_index()\n",
    "label = label.sort_index()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, label.iloc[:,0], test_size=0.3, random_state=666)\n",
    "\n",
    "#搭建融合后的模型\n",
    "inputs = Input((X_train.shape[1:]))\n",
    "x = Dropout(0.7)(inputs)\n",
    "x = Dense(22, activation='softmax')(x)\n",
    "model = Model(inputs, x)\n",
    "\n",
    "\n",
    "########################################\n",
    "early_stop = EarlyStopping(monitor='val_loss', verbose=1,\n",
    "                           patience=300,\n",
    "                           )\n",
    "\n",
    "model_file ='./model/checkpoint/ensemble.h5'\n",
    "check_best = ModelCheckpoint(filepath= model_file,\n",
    "                             monitor='val_loss', verbose=1,\n",
    "                             save_best_only=True, mode='min')\n",
    "\n",
    "from keras.utils import np_utils\n",
    "adam = Adam(0.0001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam,\n",
    "              # loss=\"binary_crossentropy\", optimizer=\"adam\",\n",
    "              # metrics=[\"accuracy\"]\n",
    "              )\n",
    "\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "\n",
    "print(np_utils.to_categorical(y_train).shape)\n",
    "\n",
    "history = model.fit(X_train, np_utils.to_categorical(y_train),\n",
    "                    validation_data=(X_test, np_utils.to_categorical(y_test)),\n",
    "                    callbacks=[check_best, early_stop],\n",
    "                    batch_size=128,\n",
    "                    # steps_per_epoch= len(X_test)//128,\n",
    "                    epochs=2,\n",
    "                    verbose=1,\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'keras.engine.training.Model'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_add_inbound_node',\n",
       " '_built',\n",
       " '_check_num_samples',\n",
       " '_check_trainable_weights_consistency',\n",
       " '_collected_trainable_weights',\n",
       " '_container_nodes',\n",
       " '_feed_input_names',\n",
       " '_feed_input_shapes',\n",
       " '_feed_inputs',\n",
       " '_feed_loss_fns',\n",
       " '_feed_output_names',\n",
       " '_feed_output_shapes',\n",
       " '_feed_outputs',\n",
       " '_feed_sample_weight_modes',\n",
       " '_feed_sample_weights',\n",
       " '_feed_targets',\n",
       " '_fit_loop',\n",
       " '_function_kwargs',\n",
       " '_get_node_attribute_at_index',\n",
       " '_inbound_nodes',\n",
       " '_internal_input_shapes',\n",
       " '_internal_output_shapes',\n",
       " '_make_predict_function',\n",
       " '_make_test_function',\n",
       " '_make_train_function',\n",
       " '_node_key',\n",
       " '_nodes_by_depth',\n",
       " '_outbound_nodes',\n",
       " '_output_mask_cache',\n",
       " '_output_shape_cache',\n",
       " '_output_tensor_cache',\n",
       " '_per_input_losses',\n",
       " '_per_input_updates',\n",
       " '_predict_loop',\n",
       " '_standardize_user_data',\n",
       " '_test_loop',\n",
       " '_updated_config',\n",
       " 'add_loss',\n",
       " 'add_update',\n",
       " 'add_weight',\n",
       " 'assert_input_compatibility',\n",
       " 'build',\n",
       " 'built',\n",
       " 'call',\n",
       " 'compile',\n",
       " 'compute_mask',\n",
       " 'compute_output_shape',\n",
       " 'count_params',\n",
       " 'evaluate',\n",
       " 'evaluate_generator',\n",
       " 'fit',\n",
       " 'fit_generator',\n",
       " 'from_config',\n",
       " 'get_config',\n",
       " 'get_input_at',\n",
       " 'get_input_mask_at',\n",
       " 'get_input_shape_at',\n",
       " 'get_layer',\n",
       " 'get_losses_for',\n",
       " 'get_output_at',\n",
       " 'get_output_mask_at',\n",
       " 'get_output_shape_at',\n",
       " 'get_updates_for',\n",
       " 'get_weights',\n",
       " 'input',\n",
       " 'input_layers',\n",
       " 'input_layers_node_indices',\n",
       " 'input_layers_tensor_indices',\n",
       " 'input_mask',\n",
       " 'input_names',\n",
       " 'input_shape',\n",
       " 'input_spec',\n",
       " 'inputs',\n",
       " 'layers',\n",
       " 'layers_by_depth',\n",
       " 'load_weights',\n",
       " 'loss',\n",
       " 'loss_functions',\n",
       " 'loss_weights',\n",
       " 'losses',\n",
       " 'metrics',\n",
       " 'metrics_names',\n",
       " 'metrics_tensors',\n",
       " 'metrics_updates',\n",
       " 'name',\n",
       " 'non_trainable_weights',\n",
       " 'optimizer',\n",
       " 'output',\n",
       " 'output_layers',\n",
       " 'output_layers_node_indices',\n",
       " 'output_layers_tensor_indices',\n",
       " 'output_mask',\n",
       " 'output_names',\n",
       " 'output_shape',\n",
       " 'outputs',\n",
       " 'predict',\n",
       " 'predict_function',\n",
       " 'predict_generator',\n",
       " 'predict_on_batch',\n",
       " 'reset_states',\n",
       " 'run_internal_graph',\n",
       " 'sample_weight_mode',\n",
       " 'sample_weight_modes',\n",
       " 'sample_weights',\n",
       " 'save',\n",
       " 'save_weights',\n",
       " 'set_weights',\n",
       " 'state_updates',\n",
       " 'stateful',\n",
       " 'stateful_metric_functions',\n",
       " 'stateful_metric_names',\n",
       " 'summary',\n",
       " 'supports_masking',\n",
       " 'targets',\n",
       " 'test_function',\n",
       " 'test_on_batch',\n",
       " 'to_json',\n",
       " 'to_yaml',\n",
       " 'total_loss',\n",
       " 'train_function',\n",
       " 'train_on_batch',\n",
       " 'trainable',\n",
       " 'trainable_weights',\n",
       " 'updates',\n",
       " 'uses_learning_phase',\n",
       " 'weighted_metrics',\n",
       " 'weights']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from keras import models\n",
    "model_load = models.load_model(model_file)\n",
    "\n",
    "#\n",
    "\n",
    "print(type(model_load))\n",
    "\n",
    "dir(model_load)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_epoch = np.array(history.history['val_loss']).argmin() + 1\n",
    "best_score = np.array(history.history['val_loss']).min()\n",
    "\n",
    "#pre_x = test.drop(['sex', 'age', 'sex_age', 'device'], axis=1)\n",
    "sub = pd.DataFrame(model_load.predict_proba(test), columns=get_label_cat())\n",
    "\n",
    "\n",
    "sub['DeviceID'] = test['device'].values\n",
    "sub = sub[\n",
    "    ['DeviceID', '1-0', '1-1', '1-2', '1-3', '1-4', '1-5', '1-6', '1-7', '1-8', '1-9', '1-10', '2-0', '2-1', '2-2',\n",
    "     '2-3', '2-4', '2-5', '2-6', '2-7', '2-8', '2-9', '2-10']]\n",
    "\n",
    "file = f'./sub/ensemble_{best}_epoch_{best_epoch}.csv'\n",
    "file = replace_invalid_filename_char(file)\n",
    "logger.info(f'sub file save to {file}')\n",
    "sub = round(sub, 10)\n",
    "sub.to_csv(file, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21]\n"
     ]
    }
   ],
   "source": [
    "print( np.unique(y_train) )\n",
    "print( np.unique(y_test) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-mlogloss:3.05177\n",
      "Will train until validation_0-mlogloss hasn't improved in 50 rounds.\n",
      "[1]\tvalidation_0-mlogloss:3.01924\n",
      "[2]\tvalidation_0-mlogloss:2.99001\n",
      "[3]\tvalidation_0-mlogloss:2.96482\n",
      "[4]\tvalidation_0-mlogloss:2.94357\n",
      "[5]\tvalidation_0-mlogloss:2.92285\n",
      "[6]\tvalidation_0-mlogloss:2.90434\n",
      "[7]\tvalidation_0-mlogloss:2.88765\n",
      "[8]\tvalidation_0-mlogloss:2.87236\n",
      "[9]\tvalidation_0-mlogloss:2.8587\n",
      "[10]\tvalidation_0-mlogloss:2.84676\n",
      "[11]\tvalidation_0-mlogloss:2.8353\n",
      "[12]\tvalidation_0-mlogloss:2.82478\n",
      "[13]\tvalidation_0-mlogloss:2.81524\n",
      "[14]\tvalidation_0-mlogloss:2.80597\n",
      "[15]\tvalidation_0-mlogloss:2.79737\n",
      "[16]\tvalidation_0-mlogloss:2.79012\n",
      "[17]\tvalidation_0-mlogloss:2.78346\n",
      "[18]\tvalidation_0-mlogloss:2.77655\n",
      "[19]\tvalidation_0-mlogloss:2.77088\n",
      "{'validation_0': {'mlogloss': [3.051766, 3.019241, 2.990009, 2.964824, 2.943568, 2.922853, 2.904342, 2.887646, 2.872357, 2.858696, 2.846756, 2.835304, 2.824777, 2.815245, 2.805973, 2.797369, 2.790115, 2.783456, 2.776547, 2.770876]}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "gbm = XGBClassifier(\n",
    "                objective='multi:softprob',\n",
    "                eval_metric='mlogloss',\n",
    "                num_class=22,\n",
    "                n_estimators=20,\n",
    "                max_depth=3,\n",
    "\n",
    "                min_child_weight=1,\n",
    "                learning_rate=0.1,\n",
    "\n",
    "                silent=True,\n",
    "                gamma=0,\n",
    "                max_delta_step=0,\n",
    "                subsample=1,\n",
    "                colsample_bytree=1,\n",
    "                colsample_bylevel=1,\n",
    "                reg_alpha=1,\n",
    "                reg_lambda=1,\n",
    "                scale_pos_weight=1,\n",
    "                seed=1,\n",
    "                missing=None)\n",
    "# print(random_search.grid_scores_)\n",
    "gbm.fit(X_train, y_train,  eval_set=[(X_test, y_test)], early_stopping_rounds=50, verbose=True )\n",
    "\n",
    "results = gbm.evals_result()\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.051766,\n",
       " 3.019241,\n",
       " 2.990009,\n",
       " 2.964824,\n",
       " 2.943568,\n",
       " 2.922853,\n",
       " 2.904342,\n",
       " 2.887646,\n",
       " 2.872357,\n",
       " 2.858696,\n",
       " 2.846756,\n",
       " 2.835304,\n",
       " 2.824777,\n",
       " 2.815245,\n",
       " 2.805973,\n",
       " 2.797369,\n",
       " 2.790115,\n",
       " 2.783456,\n",
       " 2.776547,\n",
       " 2.770876]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20_2.770876\n"
     ]
    }
   ],
   "source": [
    "best_epoch = np.array(results['validation_0']['mlogloss']).argmin()+1\n",
    "best_score = np.array(results['validation_0']['mlogloss']).min()\n",
    "\n",
    "print(f'{best_epoch}_{best_score}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
